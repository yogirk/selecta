# Selecta Agent (ADK)

This directory contains the Selecta Google ADK agent that translates natural-language questions about the configured BigQuery dataset into SQL, executes the query, and streams structured results back to clients via the official ADK API server.

## Overview
- `selecta/agent.py` builds the `root_agent` exported through `backend/app/__init__.py`, which is what `adk api_server` loads.
- `selecta/custom_tools.py` runs BigQuery queries and attaches normalized rows + auto-generated Vega-Lite specs to the ADK session state for streaming UI updates.
- `selecta/config_loader.py`, `selecta/instructions.py`, and `selecta/visualization.py` provide dataset configuration, prompt context, and chart heuristics respectively.

## Requirements
- Python 3.12+
- [`uv`](https://docs.astral.sh/uv/) for dependency management
- Google Cloud credentials for BigQuery + Gemini
- Optional: [`gcloud`](https://cloud.google.com/sdk/docs/install) to set up Application Default Credentials

## Setup
```bash
cd backend
uv venv
source .venv/bin/activate
uv pip install -e .

# Configure credentials
export GOOGLE_API_KEY="YOUR_GEMINI_KEY"      # or set Vertex AI env vars
export GOOGLE_GENAI_USE_VERTEXAI=0            # set to 1 for Vertex AI
export SELECTA_DATASET_CONFIG="$(pwd)/selecta/datasets/thelook.yaml"
```

## Run the ADK API server
```bash
uv run adk api_server app --allow_origins "*" --port 8080
```
This exposes the standard ADK REST/SSE endpoints at the root (e.g. `POST /run_sse`, `POST /apps/.../sessions`). Frontends and tools should consume these directly.

## Optional: ADK Web Playground
```bash
uv run adk web --agent selecta.agent:selecta_agent --port 8501
```

## Dataset Configuration
Copy the default dataset descriptor and adapt as needed:
```bash
cp selecta/datasets/thelook.yaml my_dataset.yaml
export SELECTA_DATASET_CONFIG="$(pwd)/my_dataset.yaml"
```
Key fields:
- Billing/data project IDs
- Dataset + tables list
- Prompt instruction file (relative paths are resolved from the YAML location)

## Quick Verification

```bash
# docs
curl http://localhost:8080/docs

# create session
SESSION=$(uuidgen); USER=u_demo
curl -X POST "http://localhost:8080/apps/app/users/$USER/sessions/$SESSION" \
  -H "Content-Type: application/json" -d "{}"

# stream a question
curl -N -X POST http://localhost:8080/run_sse \
  -H "Content-Type: application/json" \
  -d "{\"appName\":\"app\",\"userId\":\"$USER\",\"sessionId\":\"$SESSION\", \
       \"newMessage\":{\"parts\":[{\"text\":\"What is the total number of cancelled orders per month?\"}],\"role\":\"user\"}, \
       \"streaming\":true}"
```

## Result payload shape

Each streamed increment enriches the ADK `Event` with a structured result object so clients can render tables, charts, and execution metadata without extra calls. The important fields are:

| Field | Description |
| --- | --- |
| `id` | Stable UUID for the execution. |
| `sql` | GoogleSQL query executed against BigQuery. |
| `rows` / `columns` / `rowCount` | Result set (lightly normalised) for quick previews. |
| `chart` | Vega-Lite specification generated by the heuristic visualiser. |
| `summary`, `resultsMarkdown`, `businessInsights` | Structured Markdown sections emitted by the agent. |
| `createdAt` | Millisecond epoch for the execution completion time. |
| `executionMs` / `jobId` | BigQuery runtime metrics useful for observability. |
| `dataset` | Active dataset descriptor (ids, location, table allowlist). |

See `backend/api-contract.md` for the full JSON example and endpoint catalogue.

## Deployment Notes

The project now relies entirely on the ADK server; Extra FastAPI. or Flask backend is not needed.
